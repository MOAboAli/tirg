{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiAvBYJpH4cp",
        "outputId": "7f401ba9-4786-4192-a93f-ce6209b0f50a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "CPU\n",
            "(205528, 512) (205528, 512)\n",
            "Load Saved Model From Google Drive\n",
            "iteration: 0 total loss avg loss tensor(0.0430, grad_fn=<MseLossBackward0>)\n",
            "iteration: 50 total loss avg loss tensor(0.0422, grad_fn=<MseLossBackward0>)\n",
            "iteration: 100 total loss avg loss tensor(0.0415, grad_fn=<MseLossBackward0>)\n",
            "iteration: 150 total loss avg loss tensor(0.0409, grad_fn=<MseLossBackward0>)\n",
            "iteration: 200 total loss avg loss tensor(0.0404, grad_fn=<MseLossBackward0>)\n",
            "iteration: 250 total loss avg loss tensor(0.0398, grad_fn=<MseLossBackward0>)\n",
            "iteration: 300 total loss avg loss tensor(0.0394, grad_fn=<MseLossBackward0>)\n",
            "iteration: 350 total loss avg loss tensor(0.0389, grad_fn=<MseLossBackward0>)\n",
            "iteration: 400 total loss avg loss tensor(0.0385, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from numpy.core.fromnumeric import argsort, mean, squeeze\n",
        "from torch import tensor\n",
        "from torch.functional import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import math as m\n",
        "import time\n",
        "import os \n",
        "import random\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive') \n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"GPU\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"CPU\")\n",
        "class NLR3(nn.Module):\n",
        "    def __init__(self,netin,netout,nethidden):\n",
        "      super().__init__()\n",
        "      self.netmodel= torch.nn.Sequential(torch.nn.Linear(netin, nethidden),torch.nn.Sigmoid(),torch.nn.Linear(nethidden, netout))\n",
        "    def myforward (self,inv):\n",
        "      outv=self.netmodel(inv)\n",
        "      return outv\n",
        "with open('/gdrive/My Drive/dataset2/NetAtargetjn.txt', 'rb') as fp:\n",
        "       inp1=pickle.load( fp)\n",
        "with open('/gdrive/My Drive/dataset2/modjn.txt', 'rb') as fp:\n",
        "       inp2=pickle.load( fp)\n",
        "\n",
        "with open('/gdrive/My Drive/dataset2/NetBinpjn.txt', 'rb') as fp:\n",
        "       target=pickle.load( fp)\n",
        "\n",
        "\n",
        "\n",
        "target=torch.tensor(target).to(device)\n",
        "\n",
        "inp1=np.array(inp1)\n",
        "inp2=np.array(inp2)\n",
        "#inp1=numpy.squeeze(inp1)\n",
        "print(inp1.shape, inp2.shape)\n",
        "inp=np.concatenate((inp1,inp2),axis=1)\n",
        "\n",
        "del inp1, inp2\n",
        "inp=torch.tensor(inp).to(device)\n",
        "hidden=1800\n",
        "l_r=0.2\n",
        "save_duration=50\n",
        "epoch=250000\n",
        "model_mlp=NLR3(inp.shape[1],target.shape[1],hidden)\n",
        "if(os.path.isfile('/gdrive/My Drive/dataset/UltraNetCtune.pth')):\n",
        "  print('Load Saved Model From Google Drive')\n",
        "  model_mlp.load_state_dict(torch.load( '/gdrive/My Drive/dataset/UltraNetCtune.pth', map_location=(device) ))\n",
        "\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer=torch.optim.SGD(model_mlp.parameters(), lr=l_r)\n",
        "\n",
        "for j in range(epoch):\n",
        "    \n",
        "    netout=model_mlp.myforward(inp).to(device)\n",
        "    loss = loss_fn(target,netout)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if(j%save_duration==0):\n",
        "      print('iteration:',j, 'total loss','avg loss', loss)\n",
        "      torch.save(model_mlp.state_dict(), '/gdrive/My Drive/dataset/UltraNetCtune.pth')\n",
        "       #print('model & Loss  saved ')\n",
        "\n",
        " \n",
        "\n",
        "print('Finished Training')\n",
        "torch.save(model_mlp.state_dict(), '/gdrive/My Drive/dataset/Final_NetCtune.pth')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ulteraNetC.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
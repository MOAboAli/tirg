{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh8NabGrMEM3",
        "outputId": "39e45198-8ab8-4ba8-eb43-d40b4bd65225"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "GPU\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load Saved Model From Google Drive\n",
            "iteration: 0 total loss tensor(3.3878, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0177, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 150 total loss tensor(3.3273, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 300 total loss tensor(3.3451, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0175, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 450 total loss tensor(3.2592, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 600 total loss tensor(3.2895, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 750 total loss tensor(3.2443, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 900 total loss tensor(3.3533, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0175, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 1050 total loss tensor(3.2968, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 1200 total loss tensor(3.3000, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 1350 total loss tensor(3.2847, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 1500 total loss tensor(3.2872, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 1650 total loss tensor(3.2695, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 1800 total loss tensor(3.2658, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 1950 total loss tensor(3.2469, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 2100 total loss tensor(3.3713, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0176, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 2250 total loss tensor(3.3476, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0175, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 2400 total loss tensor(3.2418, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 2550 total loss tensor(3.3013, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 2700 total loss tensor(3.3010, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 2850 total loss tensor(3.2526, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 3000 total loss tensor(3.2510, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 3150 total loss tensor(3.3069, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 3300 total loss tensor(3.2701, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 3450 total loss tensor(3.2750, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 3600 total loss tensor(3.2300, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 3750 total loss tensor(3.2471, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 3900 total loss tensor(3.2512, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 4050 total loss tensor(3.2351, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 4200 total loss tensor(3.2307, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 4350 total loss tensor(3.2736, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 4500 total loss tensor(3.2128, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 4650 total loss tensor(3.2847, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 4800 total loss tensor(3.2650, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 4950 total loss tensor(3.2400, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 5100 total loss tensor(3.2365, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 5250 total loss tensor(3.2000, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 5400 total loss tensor(3.2549, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 5550 total loss tensor(3.3481, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0175, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 5700 total loss tensor(3.2466, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 5850 total loss tensor(3.2461, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 6000 total loss tensor(3.2145, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 6150 total loss tensor(3.3435, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0175, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 6300 total loss tensor(3.1835, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 6450 total loss tensor(3.2478, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 6600 total loss tensor(3.2015, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 6750 total loss tensor(3.2598, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 6900 total loss tensor(3.2268, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 7050 total loss tensor(3.2010, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 7200 total loss tensor(3.2380, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 7350 total loss tensor(3.2248, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 7500 total loss tensor(3.2904, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 7650 total loss tensor(3.2164, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 7800 total loss tensor(3.1879, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 7950 total loss tensor(3.2296, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 8100 total loss tensor(3.2075, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 8250 total loss tensor(3.3572, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0176, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 8400 total loss tensor(3.2705, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 8550 total loss tensor(3.2227, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 8700 total loss tensor(3.2496, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 8850 total loss tensor(3.3209, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 9000 total loss tensor(3.2413, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 9150 total loss tensor(3.2109, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 9300 total loss tensor(3.2570, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 9450 total loss tensor(3.2101, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 9600 total loss tensor(3.2115, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 9750 total loss tensor(3.1888, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 9900 total loss tensor(3.2701, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 10050 total loss tensor(3.2145, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 10200 total loss tensor(3.2217, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 10350 total loss tensor(3.2158, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 10500 total loss tensor(3.2445, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 10650 total loss tensor(3.2390, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 10800 total loss tensor(3.2121, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 10950 total loss tensor(3.2085, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 11100 total loss tensor(3.3092, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 11250 total loss tensor(3.2348, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 11400 total loss tensor(3.2320, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 11550 total loss tensor(3.1616, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 11700 total loss tensor(3.2045, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 11850 total loss tensor(3.1459, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 12000 total loss tensor(3.2063, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 12150 total loss tensor(3.2019, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 12300 total loss tensor(3.2060, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 12450 total loss tensor(3.1808, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 12600 total loss tensor(3.1832, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 12750 total loss tensor(3.1859, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 12900 total loss tensor(3.1655, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 13050 total loss tensor(3.1640, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 13200 total loss tensor(3.2276, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 13350 total loss tensor(3.2514, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 13500 total loss tensor(3.1439, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 13650 total loss tensor(3.2163, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 13800 total loss tensor(3.2016, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 13950 total loss tensor(3.1567, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 14100 total loss tensor(3.1586, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 14250 total loss tensor(3.2177, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 14400 total loss tensor(3.1793, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 14550 total loss tensor(3.1802, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 14700 total loss tensor(3.1274, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 14850 total loss tensor(3.1764, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 15000 total loss tensor(3.1854, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 15150 total loss tensor(3.1408, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 15300 total loss tensor(3.1359, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 15450 total loss tensor(3.1764, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 15600 total loss tensor(3.1175, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 15750 total loss tensor(3.1926, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 15900 total loss tensor(3.1671, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 16050 total loss tensor(3.1523, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 16200 total loss tensor(3.1449, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 16350 total loss tensor(3.1159, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 16500 total loss tensor(3.1725, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 16650 total loss tensor(3.2681, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 16800 total loss tensor(3.1637, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 16950 total loss tensor(3.1572, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 17100 total loss tensor(3.1250, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 17250 total loss tensor(3.1936, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 17400 total loss tensor(3.0989, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 17550 total loss tensor(3.1083, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 17700 total loss tensor(3.1394, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 17850 total loss tensor(3.1703, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 18000 total loss tensor(3.1384, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 18150 total loss tensor(3.1187, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 18300 total loss tensor(3.1683, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 18450 total loss tensor(3.1370, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 18600 total loss tensor(3.1870, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 18750 total loss tensor(3.1276, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 18900 total loss tensor(3.1002, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 19050 total loss tensor(3.1165, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 19200 total loss tensor(3.1053, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 19350 total loss tensor(3.2242, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 19500 total loss tensor(3.1879, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 19650 total loss tensor(3.1494, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 19800 total loss tensor(3.1786, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 19950 total loss tensor(3.2159, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 20100 total loss tensor(3.1620, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 20250 total loss tensor(3.1148, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 20400 total loss tensor(3.1614, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 20550 total loss tensor(3.1199, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 20700 total loss tensor(3.1241, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 20850 total loss tensor(3.1080, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 21000 total loss tensor(3.1692, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 21150 total loss tensor(3.1394, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 21300 total loss tensor(3.1291, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 21450 total loss tensor(3.1236, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 21600 total loss tensor(3.1504, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 21750 total loss tensor(3.1556, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 21900 total loss tensor(3.1249, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 22050 total loss tensor(3.1250, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 22200 total loss tensor(3.2148, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 22350 total loss tensor(3.1515, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 22500 total loss tensor(3.1385, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 22650 total loss tensor(3.0844, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 22800 total loss tensor(3.1354, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 22950 total loss tensor(3.0660, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 23100 total loss tensor(3.1285, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 23250 total loss tensor(3.1138, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 23400 total loss tensor(3.1264, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 23550 total loss tensor(3.1001, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 23700 total loss tensor(3.0959, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 23850 total loss tensor(3.1183, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 24000 total loss tensor(3.0869, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 24150 total loss tensor(3.0876, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 24300 total loss tensor(3.0704, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 24450 total loss tensor(3.1733, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 24600 total loss tensor(3.0605, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 24750 total loss tensor(3.1429, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 24900 total loss tensor(3.1130, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 25050 total loss tensor(3.0743, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 25200 total loss tensor(3.0810, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 25350 total loss tensor(3.1335, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 25500 total loss tensor(3.1035, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 25650 total loss tensor(3.0966, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 25800 total loss tensor(3.0457, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 25950 total loss tensor(3.0963, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 26100 total loss tensor(3.0682, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 26250 total loss tensor(3.0803, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 26400 total loss tensor(3.0660, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 26550 total loss tensor(3.1154, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 26700 total loss tensor(3.0297, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 26850 total loss tensor(3.1223, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 27000 total loss tensor(3.0813, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 27150 total loss tensor(3.0739, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 27300 total loss tensor(3.0668, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 27450 total loss tensor(3.0424, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 27600 total loss tensor(3.0925, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 27750 total loss tensor(3.2070, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 27900 total loss tensor(3.0902, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 28050 total loss tensor(3.0793, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 28200 total loss tensor(3.0515, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 28350 total loss tensor(3.0676, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 28500 total loss tensor(3.0373, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 28650 total loss tensor(3.0301, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 28800 total loss tensor(3.0810, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 28950 total loss tensor(3.0731, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 29100 total loss tensor(3.0658, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 29250 total loss tensor(3.0444, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 29400 total loss tensor(3.1011, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 29550 total loss tensor(3.0591, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 29700 total loss tensor(3.1123, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 29850 total loss tensor(3.0506, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 30000 total loss tensor(3.0369, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 30150 total loss tensor(3.0327, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 30300 total loss tensor(3.0237, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 30450 total loss tensor(3.0236, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 30600 total loss tensor(3.0177, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 30750 total loss tensor(3.0244, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 30900 total loss tensor(3.0710, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 31050 total loss tensor(3.1690, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 31200 total loss tensor(3.1003, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 31350 total loss tensor(3.0506, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 31500 total loss tensor(3.0936, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 31650 total loss tensor(3.0469, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 31800 total loss tensor(3.0387, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 31950 total loss tensor(3.0229, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 32100 total loss tensor(3.0614, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 32250 total loss tensor(3.0711, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 32400 total loss tensor(3.0447, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 32550 total loss tensor(3.0332, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 32700 total loss tensor(3.0741, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 32850 total loss tensor(3.0867, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 33000 total loss tensor(3.0486, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 33150 total loss tensor(3.0542, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 33300 total loss tensor(3.1317, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 33450 total loss tensor(3.0786, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 33600 total loss tensor(3.0637, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 33750 total loss tensor(3.0180, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 33900 total loss tensor(3.0769, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 34050 total loss tensor(2.9929, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 34200 total loss tensor(3.0809, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 34350 total loss tensor(3.0348, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 34500 total loss tensor(3.0588, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 34650 total loss tensor(3.0336, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 34800 total loss tensor(3.0225, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 34950 total loss tensor(3.0578, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 35100 total loss tensor(3.0202, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 35250 total loss tensor(3.0158, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 35400 total loss tensor(2.9959, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 35550 total loss tensor(3.1038, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 35700 total loss tensor(2.9928, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 35850 total loss tensor(3.0712, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 36000 total loss tensor(3.0365, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 36150 total loss tensor(3.0022, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 36300 total loss tensor(3.0155, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 36450 total loss tensor(3.0526, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 36600 total loss tensor(3.0402, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 36750 total loss tensor(3.0218, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 36900 total loss tensor(2.9775, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 37050 total loss tensor(3.0295, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 37200 total loss tensor(3.0075, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 37350 total loss tensor(2.9837, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 37500 total loss tensor(3.0101, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 37650 total loss tensor(3.0388, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 37800 total loss tensor(2.9694, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 37950 total loss tensor(3.0507, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 38100 total loss tensor(3.0059, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 38250 total loss tensor(3.0035, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 38400 total loss tensor(2.9972, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 38550 total loss tensor(2.9776, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 38700 total loss tensor(3.0234, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 38850 total loss tensor(3.1524, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 39000 total loss tensor(3.0254, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 39150 total loss tensor(3.0159, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 39300 total loss tensor(2.9867, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 39450 total loss tensor(2.9753, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 39600 total loss tensor(2.9889, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 39750 total loss tensor(2.9644, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 39900 total loss tensor(3.0130, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 40050 total loss tensor(2.9915, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 40200 total loss tensor(3.0055, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 40350 total loss tensor(2.9722, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 40500 total loss tensor(3.0374, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 40650 total loss tensor(2.9905, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 40800 total loss tensor(3.0498, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 40950 total loss tensor(2.9833, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 41100 total loss tensor(2.9793, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 41250 total loss tensor(2.9643, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 41400 total loss tensor(2.9609, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 41550 total loss tensor(2.9461, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 41700 total loss tensor(2.9467, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 41850 total loss tensor(2.9556, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 42000 total loss tensor(3.0023, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 42150 total loss tensor(3.0957, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 42300 total loss tensor(3.0325, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 42450 total loss tensor(2.9833, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 42600 total loss tensor(3.0312, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 42750 total loss tensor(2.9832, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 42900 total loss tensor(2.9700, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 43050 total loss tensor(2.9616, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 43200 total loss tensor(2.9637, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 43350 total loss tensor(3.0041, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 43500 total loss tensor(2.9824, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 43650 total loss tensor(2.9531, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 43800 total loss tensor(3.0064, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 43950 total loss tensor(3.0248, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 44100 total loss tensor(2.9811, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 44250 total loss tensor(2.9897, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 44400 total loss tensor(3.0567, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 44550 total loss tensor(3.0145, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 44700 total loss tensor(2.9991, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 44850 total loss tensor(2.9622, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 45000 total loss tensor(3.0125, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 45150 total loss tensor(2.9315, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 45300 total loss tensor(3.0111, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 45450 total loss tensor(2.9748, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 45600 total loss tensor(3.0018, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 45750 total loss tensor(2.9685, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 45900 total loss tensor(2.9594, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 46050 total loss tensor(3.0062, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 46200 total loss tensor(2.9598, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 46350 total loss tensor(2.9555, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 46500 total loss tensor(2.9332, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 46650 total loss tensor(3.0339, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 46800 total loss tensor(2.9331, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 46950 total loss tensor(3.0131, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 47100 total loss tensor(2.9712, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 47250 total loss tensor(2.9397, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 47400 total loss tensor(2.9567, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 47550 total loss tensor(2.9793, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 47700 total loss tensor(2.9835, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 47850 total loss tensor(2.9620, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 48000 total loss tensor(2.9215, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 48150 total loss tensor(2.9647, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 48300 total loss tensor(2.9490, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 48450 total loss tensor(2.9237, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 48600 total loss tensor(2.9543, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 48750 total loss tensor(2.9525, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 48900 total loss tensor(2.9129, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 49050 total loss tensor(2.9809, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 49200 total loss tensor(2.9428, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 49350 total loss tensor(2.9405, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 49500 total loss tensor(2.9391, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 49650 total loss tensor(2.9200, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 49800 total loss tensor(2.9574, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 49950 total loss tensor(3.1012, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 50100 total loss tensor(2.9680, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 50250 total loss tensor(2.9603, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 50400 total loss tensor(2.9280, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 50550 total loss tensor(2.9112, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 50700 total loss tensor(2.9394, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 50850 total loss tensor(2.9117, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 51000 total loss tensor(2.9476, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 51150 total loss tensor(2.9277, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 51300 total loss tensor(2.9508, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 51450 total loss tensor(2.9130, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 51600 total loss tensor(2.9784, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 51750 total loss tensor(2.9307, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 51900 total loss tensor(2.9956, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 52050 total loss tensor(2.9238, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 52200 total loss tensor(2.9239, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 52350 total loss tensor(2.9062, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 52500 total loss tensor(2.9050, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 52650 total loss tensor(2.8886, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 52800 total loss tensor(2.9059, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 52950 total loss tensor(2.8774, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 53100 total loss tensor(3.0318, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 53250 total loss tensor(2.9718, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 53400 total loss tensor(2.9710, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 53550 total loss tensor(2.9060, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 53700 total loss tensor(2.9579, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 53850 total loss tensor(2.9270, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 54000 total loss tensor(2.9097, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 54150 total loss tensor(2.9262, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 54300 total loss tensor(2.8981, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 54450 total loss tensor(2.9389, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 54600 total loss tensor(2.9284, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 54750 total loss tensor(2.8939, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 54900 total loss tensor(2.9435, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 55050 total loss tensor(2.9659, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 55200 total loss tensor(2.9220, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 55350 total loss tensor(2.9296, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 55500 total loss tensor(2.9913, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 55650 total loss tensor(2.9586, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 55800 total loss tensor(2.9417, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 55950 total loss tensor(2.9147, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 56100 total loss tensor(2.9234, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 56250 total loss tensor(2.8982, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 56400 total loss tensor(2.9102, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 56550 total loss tensor(2.9243, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 56700 total loss tensor(2.9517, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 56850 total loss tensor(2.9137, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 57000 total loss tensor(2.9024, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 57150 total loss tensor(2.9565, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 57300 total loss tensor(2.9068, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 57450 total loss tensor(2.9008, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 57600 total loss tensor(2.8757, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 57750 total loss tensor(2.9670, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 57900 total loss tensor(2.8801, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 58050 total loss tensor(2.9656, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 58200 total loss tensor(2.9141, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 58350 total loss tensor(2.8841, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 58500 total loss tensor(2.9054, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 58650 total loss tensor(2.9143, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 58800 total loss tensor(2.9357, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 58950 total loss tensor(2.9022, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 59100 total loss tensor(2.8703, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 59250 total loss tensor(2.9111, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 59400 total loss tensor(2.8989, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 59550 total loss tensor(2.8675, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 59700 total loss tensor(2.9052, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 59850 total loss tensor(2.8688, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 60000 total loss tensor(2.8640, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 60150 total loss tensor(2.9110, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 60300 total loss tensor(2.8843, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 60450 total loss tensor(2.8789, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 60600 total loss tensor(2.8893, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 60750 total loss tensor(2.8693, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 60900 total loss tensor(2.8970, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 61050 total loss tensor(3.0552, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 61200 total loss tensor(2.9173, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 61350 total loss tensor(2.9104, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 61500 total loss tensor(2.8790, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 61650 total loss tensor(2.8541, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 61800 total loss tensor(2.8983, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 61950 total loss tensor(2.8672, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 62100 total loss tensor(2.8913, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 62250 total loss tensor(2.8697, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 62400 total loss tensor(2.9028, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 62550 total loss tensor(2.8615, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 62700 total loss tensor(2.9251, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 62850 total loss tensor(2.8788, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 63000 total loss tensor(2.9507, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 63150 total loss tensor(2.8726, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 63300 total loss tensor(2.8695, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 63450 total loss tensor(2.8571, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 63600 total loss tensor(2.8548, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 63750 total loss tensor(2.8395, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 63900 total loss tensor(2.8860, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 64050 total loss tensor(2.8414, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 64200 total loss tensor(2.9420, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 64350 total loss tensor(2.9080, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 64500 total loss tensor(2.9159, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 64650 total loss tensor(2.8492, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 64800 total loss tensor(2.9077, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 64950 total loss tensor(2.8734, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 65100 total loss tensor(2.8603, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 65250 total loss tensor(2.9088, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 65400 total loss tensor(2.8407, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 65550 total loss tensor(2.8883, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 65700 total loss tensor(2.8763, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 65850 total loss tensor(2.8428, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 66000 total loss tensor(2.8857, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 66150 total loss tensor(2.9115, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 66300 total loss tensor(2.8698, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 66450 total loss tensor(2.8747, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 66600 total loss tensor(2.9345, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 66750 total loss tensor(2.9092, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 66900 total loss tensor(2.8906, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 67050 total loss tensor(2.8730, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 67200 total loss tensor(2.8535, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 67350 total loss tensor(2.8685, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 67500 total loss tensor(2.8495, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 67650 total loss tensor(2.8776, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 67800 total loss tensor(2.9057, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 67950 total loss tensor(2.8668, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 68100 total loss tensor(2.8541, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 68250 total loss tensor(2.9079, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 68400 total loss tensor(2.8588, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 68550 total loss tensor(2.8528, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 68700 total loss tensor(2.8227, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 68850 total loss tensor(2.9061, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 69000 total loss tensor(2.8353, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 69150 total loss tensor(2.9223, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 69300 total loss tensor(2.8644, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 69450 total loss tensor(2.8339, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 69600 total loss tensor(2.8567, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 69750 total loss tensor(2.8582, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 69900 total loss tensor(2.8885, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 70050 total loss tensor(2.8563, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 70200 total loss tensor(2.8207, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 70350 total loss tensor(2.8684, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 70500 total loss tensor(2.8505, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 70650 total loss tensor(2.8211, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 70800 total loss tensor(2.8561, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 70950 total loss tensor(2.8079, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 71100 total loss tensor(2.8145, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 71250 total loss tensor(2.8549, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 71400 total loss tensor(2.8321, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 71550 total loss tensor(2.8212, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 71700 total loss tensor(2.8496, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 71850 total loss tensor(2.8156, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 72000 total loss tensor(2.8417, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 72150 total loss tensor(3.0036, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 72300 total loss tensor(2.8705, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 72450 total loss tensor(2.8652, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 72600 total loss tensor(2.8336, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 72750 total loss tensor(2.8061, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 72900 total loss tensor(2.8571, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 73050 total loss tensor(2.8261, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 73200 total loss tensor(2.8423, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 73350 total loss tensor(2.8173, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 73500 total loss tensor(2.8575, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 73650 total loss tensor(2.8157, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 73800 total loss tensor(2.8768, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 73950 total loss tensor(2.8328, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 74100 total loss tensor(2.9065, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 74250 total loss tensor(2.8267, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 74400 total loss tensor(2.8205, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 74550 total loss tensor(2.8118, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 74700 total loss tensor(2.8107, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 74850 total loss tensor(2.7932, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 75000 total loss tensor(2.8588, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 75150 total loss tensor(2.8080, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 75300 total loss tensor(2.8812, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 75450 total loss tensor(2.8564, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 75600 total loss tensor(2.8690, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 75750 total loss tensor(2.8028, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 75900 total loss tensor(2.8661, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 76050 total loss tensor(2.8262, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 76200 total loss tensor(2.8143, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 76350 total loss tensor(2.8752, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 76500 total loss tensor(2.7919, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 76650 total loss tensor(2.8433, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 76800 total loss tensor(2.8303, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 76950 total loss tensor(2.7980, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 77100 total loss tensor(2.8353, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 77250 total loss tensor(2.8621, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 77400 total loss tensor(2.8229, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 77550 total loss tensor(2.8252, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 77700 total loss tensor(2.8837, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 77850 total loss tensor(2.8638, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 78000 total loss tensor(2.8440, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 78150 total loss tensor(2.8347, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 78300 total loss tensor(2.7992, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 78450 total loss tensor(2.8360, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 78600 total loss tensor(2.8022, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 78750 total loss tensor(2.8355, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 78900 total loss tensor(2.8630, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 79050 total loss tensor(2.8243, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 79200 total loss tensor(2.8107, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 79350 total loss tensor(2.8620, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 79500 total loss tensor(2.8150, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 79650 total loss tensor(2.8099, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 79800 total loss tensor(2.7768, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 79950 total loss tensor(2.8497, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 80100 total loss tensor(2.7992, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 80250 total loss tensor(2.8885, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 80400 total loss tensor(2.8201, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 80550 total loss tensor(2.7890, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 80700 total loss tensor(2.8117, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 80850 total loss tensor(2.8063, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 81000 total loss tensor(2.8450, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 81150 total loss tensor(2.8159, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 81300 total loss tensor(2.7764, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 81450 total loss tensor(2.8278, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 81600 total loss tensor(2.8077, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 81750 total loss tensor(2.7791, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 81900 total loss tensor(2.8108, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 82050 total loss tensor(2.7583, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 82200 total loss tensor(2.7683, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 82350 total loss tensor(2.8043, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 82500 total loss tensor(2.7956, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 82650 total loss tensor(2.7775, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 82800 total loss tensor(2.8170, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 82950 total loss tensor(2.7649, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 83100 total loss tensor(2.7941, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 83250 total loss tensor(2.9271, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 83400 total loss tensor(2.8273, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 83550 total loss tensor(2.8200, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 83700 total loss tensor(2.7917, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 83850 total loss tensor(2.7646, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 84000 total loss tensor(2.8190, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 84150 total loss tensor(2.7948, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 84300 total loss tensor(2.7922, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 84450 total loss tensor(2.7707, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 84600 total loss tensor(2.8162, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 84750 total loss tensor(2.7760, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 84900 total loss tensor(2.8334, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 85050 total loss tensor(2.7903, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 85200 total loss tensor(2.8667, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 85350 total loss tensor(2.7845, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 85500 total loss tensor(2.7753, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 85650 total loss tensor(2.7696, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 85800 total loss tensor(2.7700, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 85950 total loss tensor(2.7512, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 86100 total loss tensor(2.8240, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 86250 total loss tensor(2.7737, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 86400 total loss tensor(2.8280, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 86550 total loss tensor(2.8093, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 86700 total loss tensor(2.8236, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 86850 total loss tensor(2.7608, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 87000 total loss tensor(2.8293, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 87150 total loss tensor(2.7845, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 87300 total loss tensor(2.7719, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 87450 total loss tensor(2.8314, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 87600 total loss tensor(2.7475, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 87750 total loss tensor(2.8031, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 87900 total loss tensor(2.7882, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 88050 total loss tensor(2.7573, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 88200 total loss tensor(2.7901, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 88350 total loss tensor(2.8168, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 88500 total loss tensor(2.7799, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 88650 total loss tensor(2.7790, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 88800 total loss tensor(2.8379, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 88950 total loss tensor(2.8229, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 89100 total loss tensor(2.8008, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 89250 total loss tensor(2.7990, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 89400 total loss tensor(2.7529, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 89550 total loss tensor(2.8046, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 89700 total loss tensor(2.7623, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 89850 total loss tensor(2.7974, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 90000 total loss tensor(2.8237, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 90150 total loss tensor(2.7863, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 90300 total loss tensor(2.7700, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 90450 total loss tensor(2.8187, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 90600 total loss tensor(2.7743, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 90750 total loss tensor(2.7703, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 90900 total loss tensor(2.7354, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 91050 total loss tensor(2.7973, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 91200 total loss tensor(2.7682, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 91350 total loss tensor(2.8591, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 91500 total loss tensor(2.7795, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 91650 total loss tensor(2.7479, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 91800 total loss tensor(2.7699, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 91950 total loss tensor(2.7595, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 92100 total loss tensor(2.8030, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 92250 total loss tensor(2.7785, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 92400 total loss tensor(2.7365, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 92550 total loss tensor(2.7885, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 92700 total loss tensor(2.7694, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 92850 total loss tensor(2.7413, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 93000 total loss tensor(2.7679, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 93150 total loss tensor(2.7206, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0142, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 93300 total loss tensor(2.7570, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 93450 total loss tensor(2.7767, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 93600 total loss tensor(2.7788, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 93750 total loss tensor(2.7440, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 93900 total loss tensor(2.7683, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 94050 total loss tensor(2.7360, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 94200 total loss tensor(2.7384, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 94350 total loss tensor(2.8781, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 94500 total loss tensor(2.7757, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 94650 total loss tensor(2.7804, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 94800 total loss tensor(2.7511, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 94950 total loss tensor(2.7291, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 95100 total loss tensor(2.7717, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 95250 total loss tensor(2.7565, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 95400 total loss tensor(2.7518, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 95550 total loss tensor(2.7265, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 95700 total loss tensor(2.7729, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 95850 total loss tensor(2.7410, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 96000 total loss tensor(2.7920, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 96150 total loss tensor(2.7516, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 96300 total loss tensor(2.8238, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 96450 total loss tensor(2.7455, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 96600 total loss tensor(2.7326, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 96750 total loss tensor(2.7303, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 96900 total loss tensor(2.7307, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 97050 total loss tensor(2.7128, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0142, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 97200 total loss tensor(2.7783, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 97350 total loss tensor(2.7390, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 97500 total loss tensor(2.7822, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 97650 total loss tensor(2.7657, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 97800 total loss tensor(2.7799, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 97950 total loss tensor(2.7225, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0142, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 98100 total loss tensor(2.7899, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 98250 total loss tensor(2.7478, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 98400 total loss tensor(2.7316, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 98550 total loss tensor(2.7849, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 98700 total loss tensor(2.7065, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0142, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 98850 total loss tensor(2.7645, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 99000 total loss tensor(2.7502, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 99150 total loss tensor(2.7202, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0142, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 99300 total loss tensor(2.7502, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 99450 total loss tensor(2.7737, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 99600 total loss tensor(2.7405, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 99750 total loss tensor(2.7350, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "iteration: 99900 total loss tensor(2.7967, device='cuda:0', grad_fn=<AddBackward0>) avg loss tensor(0.0146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from numpy.core.fromnumeric import argsort, mean, squeeze\n",
        "from torch import tensor\n",
        "from torch.functional import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import math as m\n",
        "import time\n",
        "import os \n",
        "import random\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"GPU\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"CPU\")\n",
        "\n",
        "class NLR3(nn.Module):\n",
        "    def __init__(self,netin,netout,nethidden):\n",
        "      super().__init__()\n",
        "      self.netmodel= torch.nn.Sequential(torch.nn.Linear(netin, nethidden),torch.nn.Tanh(),torch.nn.Linear(nethidden, netout))\n",
        "    def myforward (self,inv):\n",
        "      outv=self.netmodel(inv)\n",
        "      return outv\n",
        "\n",
        "\n",
        "with open('/content/drive/My Drive/Master/Files/FeaturesToFiles172/Features172QueryStructureallF.txt', 'rb') as fp:\n",
        "       AllData=pickle.load( fp)\n",
        "\n",
        "\n",
        "target=[d['QueryCaptionF'] for d in AllData]\n",
        "inp=[d['Query152F'] for d in AllData]\n",
        "target=torch.tensor(target).to(device)\n",
        "inp=torch.tensor(inp).to(device)\n",
        "\n",
        "\n",
        "hidden=1000\n",
        "l_r=0.1\n",
        "epoch=100000\n",
        "batch_size=900\n",
        "save_duration=150\n",
        "seed=100\n",
        "min_error=0.1\n",
        "model_mlp=NLR3(inp.shape[1],target.shape[1],hidden).to(device)\n",
        "if(os.path.isfile('/content/drive/My Drive/Master/Files/SavedModels/UltraNetA152.pth')):\n",
        "  print('Load Saved Model From Google Drive')\n",
        "  model_mlp.load_state_dict(torch.load( '/content/drive/My Drive/Master/Files/SavedModels/UltraNetA152.pth', map_location=torch.device('cpu') ))\n",
        "\n",
        "loss_fn = torch.nn.MSELoss() \n",
        "optimizer=torch.optim.SGD(model_mlp.parameters(), lr=l_r)\n",
        "s=0\n",
        "sweep_range=inp.shape[0]%batch_size\n",
        "\n",
        "if(os.path.isfile('/content/drive/My Drive/Master/Files/SavedModels/UltraNetAlosses152.pkl')):\n",
        "  with open('/content/drive/My Drive/Master/Files/SavedModels/UltraNetAlosses152.pkl', 'rb') as fp:\n",
        "       totallosses=pickle.load( fp)\n",
        "       #print(totallosses)\n",
        "else:\n",
        "  totallosses=[]\n",
        "\n",
        "\n",
        "for j in range(epoch):\n",
        "  total_loss=0\n",
        "  \n",
        "  for l in range(int(inp.shape[0]/batch_size)):\n",
        "    \n",
        "    item_batch = inp[l*batch_size+s:(l+1)*batch_size+s,:]\n",
        "\n",
        "    target_batch=target[l*batch_size+s:(l+1)*batch_size+s,:]\n",
        "    netoutbatch=model_mlp.myforward(item_batch)\n",
        "    loss = loss_fn(target_batch,netoutbatch)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss+=loss\n",
        "  if (total_loss<min_error):\n",
        "    break\n",
        "  if(j%save_duration==0):\n",
        "    print('iteration:',j, 'total loss',total_loss,'avg loss', total_loss/(inp.shape[0]/batch_size))\n",
        "    torch.save(model_mlp.state_dict(), '/content/drive/My Drive/Master/Files/SavedModels/UltraNetA152.pth')\n",
        "    totallosses.append(total_loss)\n",
        "    with open('/content/drive/My Drive/Master/Files/SavedModels/UltraNetAlosses152.pkl', 'wb') as fp:\n",
        "      pickle.dump( totallosses, fp)\n",
        "    total_loss=0\n",
        "    #print('model & Loss  saved ')\n",
        "\n",
        "  s+=1\n",
        "  if s==sweep_range:\n",
        "      s=0\n",
        " \n",
        "    \n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "torch.save(model_mlp.state_dict(), '/content/drive/My Drive/Master/Files/SavedModels/Final_NetA152.pth') \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "UltraNetA152.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ulterafilteruniquequeries.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x5nexjk9vWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6861700-8e85-4ec5-90ee-5f59cc74da46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "172048\n",
            "106464\n",
            "green seamed a-line dress 0\n",
            "multicolor abstract print a-line dress 4\n",
            "multicolor abstract print a-line dress 5\n",
            "black short dress 8\n",
            "black short dress 9\n",
            "black short dress 10\n",
            "black short dress 11\n",
            "black short dress 12\n",
            "black short dress 13\n",
            "black short dress 14\n",
            "black short dress 15\n",
            "black short dress 16\n",
            "black short dress 17\n",
            "black short dress 18\n",
            "black short dress 19\n",
            "black short dress 20\n",
            "black short dress 21\n",
            "black short dress 22\n",
            "black short dress 23\n",
            "black short dress 24\n",
            "black short dress 25\n",
            "black short dress 26\n",
            "black short dress 27\n",
            "black rosie dress 28\n",
            "black rosie dress 29\n",
            "black rosie dress 30\n",
            "black rosie dress 31\n",
            "multicolor floral print shirt dress 32\n",
            "multicolor floral print shirt dress 33\n",
            "multicolor floral print shirt dress 34\n",
            "multicolor floral print shirt dress 35\n",
            "multicolor floral print shirt dress 36\n",
            "white gauze shirt dress 37\n",
            "white gauze shirt dress 38\n",
            "green midi dress 57\n",
            "green midi dress 58\n",
            "red short dress 84\n",
            "blue one shoulder dress 85\n",
            "blue one shoulder dress 86\n",
            "blue one shoulder dress 87\n",
            "blue one shoulder dress 88\n",
            "blue one shoulder dress 89\n",
            "beige scarlett dress 90\n",
            "beige scarlett dress 91\n",
            "beige scarlett dress 92\n",
            "beige scarlett dress 93\n",
            "blue knee-length dress 94\n",
            "white off-shoulder silk dress 103\n",
            "white off-shoulder silk dress 104\n",
            "white off-shoulder silk dress 105\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from numpy.core.fromnumeric import argsort, mean, squeeze\n",
        "from torch import tensor\n",
        "from torch.functional import norm\n",
        "#import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import optim\n",
        "#import math as m\n",
        "import time\n",
        "#import os \n",
        "import random\n",
        "#from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "#import tensorflow as tf\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "#import torchvision\n",
        "\n",
        "# this documnet for removing redundancy imgs in all images  \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive') \n",
        "\n",
        "run_type=0\n",
        "\n",
        "if run_type==0:\n",
        "  with open('/gdrive/My Drive/dataset/Features172QueryStructureallF.txt', 'rb') as fp:\n",
        "       AllData=pickle.load( fp)\n",
        "  \n",
        "  \n",
        "else:\n",
        "  with open('/gdrive/My Drive/dataset/Features33QueryStructureallF.txt', 'rb') as fp:\n",
        "       AllData=pickle.load( fp)\n",
        "\n",
        "allquerycaptions=[d['QueryCaption'] for d in AllData]\n",
        "idslist=[d['QueryID'] for d in AllData]\n",
        "phix_18=[d['Query18F'] for d in AllData]\n",
        "phix_50=[d['Query50F'] for d in AllData]\n",
        "phix_152=[d['Query152F'] for d in AllData]\n",
        "phix_152=np.array(phix_152)\n",
        "phix_50=np.array(phix_50)\n",
        "phix_18=np.array(phix_18)\n",
        "\n",
        "sort_index=np.argsort(idslist)\n",
        "previd=199999\n",
        "unique_query_phix_18=[]\n",
        "unique_query_phix_50=[]\n",
        "unique_query_phix_152=[]\n",
        "unique_query_img_captions=[]\n",
        "unique_sorted_query_ids=[]\n",
        "print(len(phix_50))\n",
        "\n",
        "for i in range(len(idslist)):\n",
        "  if idslist[sort_index[i]]!=previd:\n",
        "    unique_query_phix_18.append(phix_18[sort_index[i],:])\n",
        "    unique_query_phix_50.append(phix_50[sort_index[i]])\n",
        "    unique_query_phix_152.append(phix_152[sort_index[i]])\n",
        "    unique_query_img_captions.append(allquerycaptions[sort_index[i]])\n",
        "    unique_sorted_query_ids.append(idslist[sort_index[i]])\n",
        "    previd=idslist[sort_index[i]]\n",
        "\n",
        "print(len(unique_query_phix_18))\n",
        "for i in range(50):\n",
        "  print(unique_query_img_captions[i],unique_sorted_query_ids[i])\n",
        "\n",
        "if (run_type==0):\n",
        "  with open('/gdrive/My Drive/dataset/ultra_unique_query_phix_50.txt', 'wb') as fp:\n",
        "       pickle.dump(unique_query_phix_50, fp)\n",
        "  with open('/gdrive/My Drive/dataset/ultra_unique_query_phix_18.txt', 'wb') as fp:\n",
        "       pickle.dump(unique_query_phix_18, fp)\n",
        "  with open('/gdrive/My Drive/dataset/ultra_unique_query_phix_152.txt', 'wb') as fp:\n",
        "       pickle.dump(unique_query_phix_152, fp)\n",
        "  with open('/gdrive/My Drive/dataset/ultra_unique_sorted_query_ids.txt', 'wb') as fp:\n",
        "       pickle.dump(unique_sorted_query_ids, fp)\n",
        "  with open('/gdrive/My Drive/dataset/ultra_unique_query_img_captions_text.txt', 'wb') as fp:\n",
        "       pickle.dump(unique_query_img_captions, fp)\n",
        "  \n",
        "\n",
        "else:\n",
        "  with open('/gdrive/My Drive/dataset/ultra_unique_query_phix_50_test.txt', 'wb') as fp:\n",
        "       pickle.dump(unique_query_phix_50, fp)\n",
        "  with open('/gdrive/My Drive/dataset/ultra_unique_query_phix_18_test.txt', 'wb') as fp:\n",
        "       pickle.dump(unique_query_phix_18, fp)\n",
        "  with open('/gdrive/My Drive/dataset/ultra_unique_query_phix_152_test.txt', 'wb') as fp:\n",
        "       pickle.dump(unique_query_phix_152, fp)\n",
        "  with open('/gdrive/My Drive/dataset/ultra_unique_sorted_query_ids_test.txt', 'wb') as fp:\n",
        "       pickle.dump(unique_sorted_query_ids, fp)\n",
        "  with open('/gdrive/My Drive/dataset/ultra_unique_query_img_captions_text_test.txt', 'wb') as fp:\n",
        "       pickle.dump(unique_query_img_captions, fp)\n",
        "\n"
      ]
    }
  ]
}